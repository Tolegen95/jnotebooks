{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from tensorflow import keras as keras\nimport tensorflow as tf\nimport csv\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# imports needed for CNN\nimport csv\nimport cv2\nimport os, glob\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom matplotlib import pyplot as plt\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "06818ec9c90e1cf19c9915c21b0c8a35108220aa"
      },
      "cell_type": "code",
      "source": "!ls ../input/corners",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4e81433b08c15ddd097225bbf7ce45f902ef885"
      },
      "cell_type": "code",
      "source": "IMAGE_WIDTH = 255\nIMAGE_HEIGHT = 255",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16a9a99d0a52c3b73bb63c4db1049177f310a350"
      },
      "cell_type": "code",
      "source": "data = pd.read_csv('../input/corners/data.csv')\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30f508d8017d1b29f34967ec61302ad2b77f5679"
      },
      "cell_type": "code",
      "source": "def load_data(data_dir):\n    images = []\n    labels = []\n    \n    for i in range(len(data)):\n        img = cv2.imread(data_dir+data['loc'][i])\n        imresize = cv2.resize(img, (255, 255))\n        images.append(imresize)\n        labels.append([data['x'][i], data['y'][i]])\n    \n    return images, labels",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8f5284ff21ae0626ebcc14150893a1b6881ac33"
      },
      "cell_type": "code",
      "source": "data_dir = \"../input/corners/ims/\"\nimages, labels = load_data(data_dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57f9ca9de647f8c6e7cc8ecb4d496e80075209d8"
      },
      "cell_type": "code",
      "source": "print(images[0:10])\nprint(labels[0:10])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4edc448457659c5a06ae358bbaa7bdd5abc1e62c"
      },
      "cell_type": "code",
      "source": "def cross_validate(Xs, ys):\n    X_train, X_test, y_train, y_test = train_test_split(\n            Xs, ys, test_size=0.2, random_state=0)\n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = cross_validate(images, labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bbaf251633afd84b7a4c1ff5bbece6acaba75ee9"
      },
      "cell_type": "code",
      "source": "X_train = np.array(X_train).astype('float32')\nX_test = np.array(X_test).astype('float32')\nX_train = X_train / 255.0\nX_test = X_test / 255.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "70ce218b6fb871851b6e631cb7ad92d0009ea48a"
      },
      "cell_type": "code",
      "source": "print(X_train.size, X_test.size, y_train.size, y_test.size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "feb76f94370665f0d756937ef4332e463d34a6ad"
      },
      "cell_type": "code",
      "source": "print(len(y_train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27351e13ff3b2ddd7768b21bca01bbdd01670091"
      },
      "cell_type": "code",
      "source": "print(len(X_train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "caabccf3928b2dabdc0e29c0d762405c0d5f6e19"
      },
      "cell_type": "code",
      "source": "# Configure Model\n# model = keras.Sequential([keras.layers.Flatten(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n#                          keras.layers.Dense(128, activation=\"relu\"),\n#                          keras.layers.Dropout(0.1),\n#                          keras.layers.Dense(64, activation=\"relu\"),\n#                          keras.layers.Dense(2)\n#                          ])\nmodel = Sequential()\nmodel.add(Convolution2D(32, 3, 3, input_shape=(255, 255, 3), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\nmodel.add(Dropout(0.2))\nmodel.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(2))\n\nepochs = 3  # >>> should be 25+\nlrate = 0.01\ndecay = lrate/epochs\nsgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n# model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4151057f0410f52f6f875206f76c626d4f81402b"
      },
      "cell_type": "code",
      "source": "# # Compile model\nmodel.compile(optimizer=tf.train.AdamOptimizer(), \n              loss='mse',\n              metrics=['mae'])\n\nprint(model.)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb1a37eda3b8f213a788ccfc126c0001d6c85867"
      },
      "cell_type": "code",
      "source": "# Train model\n# model.fit(Xtrain, Ytrain, epochs=500)\nmodel.fit(X_train, [y_train], validation_data=(X_test, [y_test]), nb_epoch=epochs, batch_size=64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f32d24cfa561ad3b53390ef8d0c3a7bf9218d51",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Load test data\ndef load_testset():\n    Xtest = []\n    with open('../input/test/test.csv') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            img = np.zeros((IMAGE_HEIGHT,IMAGE_WIDTH,1), dtype=np.float)\n            for i, val in enumerate(row[\"Image\"].split(\" \")):\n                img[i//IMAGE_WIDTH,i%IMAGE_WIDTH,0] = val\n            Xtest.append(img)\n                \n    return np.array(Xtest)\nXtest = load_testset()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "028f793e10edae3f5e51d9c417f3ab1de1437ede",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Preview results on test data\ndef show_results(image_index):\n    Ypred = model.predict(Xtest[image_index:(image_index+1)])\n    show_image(Xtest[image_index], Ypred[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eacd1ec9f9d5906fdb01945d9f3b69c6c5e75cfb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "show_results(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4e68961d653c0423da25f6de016606c8582e7b2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "show_results(4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58eaf890e233ab51b732d60a8155c28c14fe1038",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "show_results(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48c56f649e9a6518edbd760d9784dc00fd0c9373",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def load_data(data_dir):\n    \"\"\"\n    From: https://medium.com/@waleedka/traffic-sign-recognition-with-tensorflow-629dffc391a6#.v471kaepx\n    \"\"\"\n    # Get all subdirectories of data_dir. Each represents a label.\n    directories = [d for d in os.listdir(data_dir)\n                   if os.path.isdir(os.path.join(data_dir, d))]\n    # Loop through the label directories and collect the data in\n    # two lists, labels and images.\n    labels = []\n    images = []\n\n    category = 0\n    for d in directories:\n        label_dir = os.path.join(data_dir, d)\n        file_names = [os.path.join(label_dir, f)\n                      for f in os.listdir(label_dir)\n                      if f.endswith(\".jpg\")]\n        \n        # adding an early stop for sake of speed\n        stop = 0\n        for f in file_names:\n            img = cv2.imread(f)\n            imresize = cv2.resize(img, (200, 125))\n            #plt.imshow(imresize)\n            images.append(imresize)\n            labels.append(category)\n            # remove this to use full data set\n            if stop > 30:\n                break\n            stop += 1\n            # end early stop\n            \n        category += 1\n\n    return images, labels\n\ndata_dir = \"../input\"\nimages, labels = load_data(data_dir)\n\n# confirm that we have the data\nprint(images[0:10])\nprint(labels[0:10])",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}