{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed75c34ba4f184f98645610dcf5c1d816d7e4f83"
      },
      "cell_type": "code",
      "source": "!ls ../input/train-akbars/crreal/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0cb7fd0a504285da688019dd1e576fcd9edaf3af"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87949484818c0d740126ddc7a090bb1589db1b7b"
      },
      "cell_type": "code",
      "source": "from __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7228c5ebc9af870de99465942faf91ed9c6433b0"
      },
      "cell_type": "code",
      "source": "import matplotlib as plt\nfrom PIL import ImageFont, ImageDraw, Image\nimport random as rd\nfrom IPython.display import display\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nfrom skimage import io, transform\nimport torchvision\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bef22494a5ff1f799a65c91bc0f26f332b622674"
      },
      "cell_type": "code",
      "source": "from pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom oauth2client.client import GoogleCredentials\nimport pandas as pd\nfrom sklearn import preprocessing\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75d349a76bc074cfcf7395dc26a5e0e8ec9bd955"
      },
      "cell_type": "code",
      "source": "path_image = \"../input/train-akbars/crreal/\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Top level data directory. Here we assume the format of the directory conforms\n#   to the ImageFolder structure\ndata_dir = path_image\n# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\nmodel_name = \"squeezenet\"\n\n# Number of classes in the dataset\nnum_classes = 37\n\n# Batch size for training (change depending on how much memory you have)\nbatch_size = 4\n\n# Number of epochs to train for\nnum_epochs = 3\n\n# Flag for feature extracting. When False, we finetune the whole model,\n#   when True we only update the reshaped layer params\nfeature_extract = True",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8cb67ac3d01b332241752aacf4de3872031e1486"
      },
      "cell_type": "code",
      "source": "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a9013430ec77af069c3544a3d1b49f0097d60fd"
      },
      "cell_type": "code",
      "source": "def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aec506afbf3ba75584db31f82cf7ef0770b5bfba"
      },
      "cell_type": "code",
      "source": "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # Initialize these variables which will be set in this if statement. Each of these\n    #   variables is model specific.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\n# Initialize the model for this run\nmodel_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n\n# Print the model we just instantiated\nprint(model_ft)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "baab2e297beb6285e6e41495f705d4d6e1e43fd9"
      },
      "cell_type": "code",
      "source": "!ls ../input/train-akbars/crreal/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07dd6e98e0b905332ff6a25757dca150a7f649b1"
      },
      "cell_type": "code",
      "source": "# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n#         transforms.RandomResizedCrop(input_size),\n#         transforms.RandomHorizontalFlip(),\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n#         transforms.Resize(input_size),\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\nprint(\"Initializing Datasets and Dataloaders...\")\n\n# Create training and validation datasets hui penis\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n# Create training and validation dataloaders\ndataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n\n# Detect if we have a GPU available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ada92c69552b04812d5a68d836fa398d8350c66"
      },
      "cell_type": "code",
      "source": "model_ft = model_ft.to(device)\n\n# Gather the parameters to be optimized/updated in this run. If we are\n#  finetuning we will be updating all parameters. However, if we are\n#  doing feature extract method, we will only update the parameters\n#  that we have just initialized, i.e. the parameters with requires_grad\n#  is True.\nparams_to_update = model_ft.parameters()\nprint(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c0d7eb64a19152805094a7d08514ede9248dd6e"
      },
      "cell_type": "code",
      "source": "criterion = nn.CrossEntropyLoss()\n\n# Train and evaluate\nmodel_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b7ce6939cd60c72ab6f76383317938ec1dc4220"
      },
      "cell_type": "code",
      "source": "torch.save(model_ft.state_dict(), 'vesa.a')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b2ef3d232872d51b813eba1c637909e70821d9e"
      },
      "cell_type": "code",
      "source": "# test = pd.DataFrame(columns=['card_number', 'date_expire', 'filename', 'first_name', 'last_name'])\n# test_path = '../input/test-ak-bars/test/TestImages/'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33d53e88233c181fdda331e42af3783b877ac731",
        "_kg_hide-input": false,
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "# for i in range(300):\n#     print('predict ', str(i) + ' of 300', i/300)\n#     img = Image.open(test_path+str(i)+'.png')\n#     x, y = img.size\n#     box = number_box\n#     card_digits = crop(img.crop((int(x*box['xl']), int(y*box['yu']), int(x*box['xr']), int(y*box['yd']))), 4, 4)\n#     card_number = predict_images(card_digits)\n    \n#     box = date_box\n#     date_digits =crop(img.crop((int(x*box['xl']), int(y*box['yu']), int(x*box['xr']), int(y*box['yd']))), 5, 1)\n#     date_numbers = predict_images(date_digits)\n#     ldate = list(date_numbers)\n#     ldate[2] = '/'\n#     date_numbers = \"\".join(ldate)\n    \n#     box = name_box\n#     name_char = crop(img.crop((int(x*box['xl']), int(y*box['yu']), int(x*box['xr']), int(y*box['yd']))), 13, 1)\n#     name = predict_images(name_char)\n    \n#     box = fname_box\n#     fname_char = crop(img.crop((int(x*box['xl']), int(y*box['yu']), int(x*box['xr']), int(y*box['yd']))), 13, 1)\n#     fname = predict_images(fname_char)\n    \n# #     print('creating dateframe')\n# #     pred = pd.DataFrame(data = [[card_number], [date_numbers], [str(i)+'.png'], [parse_name(name)],[parse_name(fname)]], columns=['card_number', 'date_expire', 'filename', 'first_name', 'last_name'])\n# # #     pred = pd.DataFrame(data={'card_number':[card_number], 'date_expire':[date_numbers], 'filename':[str(i)+'.png'], 'first_name':[parse_name(name)], 'last_name':[parse_name(fname)]})\n    \n# #     print('append', pred.head())\n# #     test.append(pred, ignore_index=True)\n#     test.loc[len(test)] = [card_number, date_numbers, str(i)+'.png', parse_name(name), parse_name(fname)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6699f77b7790273dd839634408e57bd05a562bcb"
      },
      "cell_type": "code",
      "source": "def get_label_from_predict(out):\n    label, mxvl = 0, 0\n    for i in range(36):\n        if mxvl < out[0][i].item():\n            mxvl = out[0][i].item()\n            label = i\n    return alpabet[label]\n\ndef crop(image, cx, cy):\n    image = image.copy()\n    x, y = image.size\n    dx, dy = int(x/cx), int(y/cy)\n    cim = []\n    for i in range(cy):  \n        for j in range(cx):\n            cim.append(image.crop((j*dx, i*dy, dx*(j+1), dy*(i+1))))\n            cim[-1] = cim[-1].resize((244, 244),Image.ANTIALIAS)\n    return cim\n\nnumber_box = {'xl': 0.06, 'xr':0.325, 'yu':0.165, 'yd':0.44}\ndate_box = {'xl':0.09, 'xr':0.31, 'yu':0.46, 'yd':0.5}\nname_box = {'xl':0.06, 'xr':0.69, 'yu':0.563, 'yd':0.605}\nfname_box = {'xl':0.06, 'xr':0.69, 'yu':0.625, 'yd':0.667}\nim_size = 244\n\ndef predict_images(ims):\n    prediction = ''\n    for k in range(len(ims)):\n        ims[k] = data_transforms['val'](ims[k])\n        shitpredict = torch.tensor([[ims[k].numpy()[0], ims[k].numpy()[1], ims[k].numpy()[2]]], device=device)\n        out = model_ft(shitpredict)\n        prediction += get_label_from_predict(out)\n    return prediction\n\ndef parse_name(name):\n    for i in range(len(name)):\n        if name[i] == '-':\n            return name[0:i]\n    return name\n\nalpabet = '-0123456789abcdefghijklmnopqrstuvwxyz'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7075ed4a7d79a17fc49a565e8e9a52758082953f"
      },
      "cell_type": "code",
      "source": "test.tail()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0363f642572a20dc5a38740fe669b3473b2bb0f4"
      },
      "cell_type": "code",
      "source": "# for i in range(len(test)):\n#     test['last_name'][i] = parse_name(test['last_name'][i])\n#     test['first_name'][i] = parse_name(test['first_name'][i])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99d48be2ddca0957a28a70c8a73b13cf9ae913fc"
      },
      "cell_type": "code",
      "source": "# test.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d085bdd5478fc11b830de0d7c319ec0f17c78d56"
      },
      "cell_type": "code",
      "source": "len(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb686f03a8786deb01a174e35608fdc3a9ed4d61"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1bcf6f51b2eb139a3ce394808b04aa2641bf0e82"
      },
      "cell_type": "code",
      "source": "from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\ndef create_download_link_csv(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ndef create_download_link_csv(df, title = \"Download CSV file\", filename = \"data.a\"):  \n    csv = df\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "917d4a048761c2bf24501e0822e8d2cb0ac0110d"
      },
      "cell_type": "code",
      "source": "# create_download_link_csv(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5690e6855147a8c35d983ba7c8eda194b02b2aa6"
      },
      "cell_type": "code",
      "source": "# create_download_link()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "86988de9fcd1300be8d1643440c785a93e4b3e74"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}